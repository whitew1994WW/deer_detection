{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deer detection\n",
    "\n",
    "This notebook uses the data from the following hugging face dataset \"myyyyw/NTLNP\" to train a small YoloV8 model to detect deer in images.\n",
    "\n",
    "The training_data folder contains the downloaded data from the dataset, which has been extracted from the rar files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import YolosImageProcessor, YolosForObjectDetection, AutoModelForObjectDetection\n",
    "import torch\n",
    "import requests\n",
    "\n",
    "\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"hustvl/yolos-tiny\")\n",
    "image_processor = YolosImageProcessor.from_pretrained(\"hustvl/yolos-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_auto_class',\n",
       " '_backward_compatibility_gradient_checkpointing',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_impl',\n",
       " '_check_and_enable_flash_attn_2',\n",
       " '_compiled_call_impl',\n",
       " '_convert_head_mask_to_5d',\n",
       " '_copy_lm_head_original_to_resized',\n",
       " '_create_repo',\n",
       " '_dispatch_accelerate_model',\n",
       " '_expand_inputs_for_generation',\n",
       " '_extract_past_from_model_output',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_always_called',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_from_config',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_decoder_start_token_id',\n",
       " '_get_files_timestamps',\n",
       " '_get_generation_mode',\n",
       " '_get_logits_processor',\n",
       " '_get_logits_warper',\n",
       " '_get_name',\n",
       " '_get_resized_embeddings',\n",
       " '_get_resized_lm_head',\n",
       " '_get_stopping_criteria',\n",
       " '_hf_peft_config_loaded',\n",
       " '_hook_rss_memory_post_forward',\n",
       " '_hook_rss_memory_pre_forward',\n",
       " '_init_weights',\n",
       " '_initialize_weights',\n",
       " '_is_full_backward_hook',\n",
       " '_is_hf_initialized',\n",
       " '_keep_in_fp32_modules',\n",
       " '_keys_to_ignore_on_load_missing',\n",
       " '_keys_to_ignore_on_load_unexpected',\n",
       " '_keys_to_ignore_on_save',\n",
       " '_load_from_state_dict',\n",
       " '_load_pretrained_model',\n",
       " '_load_pretrained_model_low_mem',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_maybe_initialize_input_ids_for_generation',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_merge_criteria_processor_list',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_no_split_modules',\n",
       " '_non_persistent_buffers_set',\n",
       " '_parameters',\n",
       " '_prepare_attention_mask_for_generation',\n",
       " '_prepare_decoder_input_ids_for_generation',\n",
       " '_prepare_encoder_decoder_kwargs_for_generation',\n",
       " '_prepare_model_inputs',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_reorder_cache',\n",
       " '_replicate_for_data_parallel',\n",
       " '_resize_token_embeddings',\n",
       " '_save_to_state_dict',\n",
       " '_set_aux_loss',\n",
       " '_set_default_torch_dtype',\n",
       " '_set_gradient_checkpointing',\n",
       " '_skip_keys_device_placement',\n",
       " '_slow_forward',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_supports_flash_attn_2',\n",
       " '_tie_encoder_decoder_weights',\n",
       " '_tie_or_clone_weights',\n",
       " '_tied_weights_keys',\n",
       " '_update_model_kwargs_for_generation',\n",
       " '_upload_modified_files',\n",
       " '_validate_generated_length',\n",
       " '_validate_model_class',\n",
       " '_validate_model_kwargs',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'active_adapter',\n",
       " 'active_adapters',\n",
       " 'add_adapter',\n",
       " 'add_memory_hooks',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'assisted_decoding',\n",
       " 'base_model',\n",
       " 'base_model_prefix',\n",
       " 'bbox_predictor',\n",
       " 'beam_sample',\n",
       " 'beam_search',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'can_generate',\n",
       " 'children',\n",
       " 'class_labels_classifier',\n",
       " 'compile',\n",
       " 'compute_transition_scores',\n",
       " 'config',\n",
       " 'config_class',\n",
       " 'constrained_beam_search',\n",
       " 'contrastive_search',\n",
       " 'cpu',\n",
       " 'create_extended_attention_mask_for_decoder',\n",
       " 'cuda',\n",
       " 'device',\n",
       " 'disable_adapters',\n",
       " 'disable_input_require_grads',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dummy_inputs',\n",
       " 'dump_patches',\n",
       " 'enable_adapters',\n",
       " 'enable_input_require_grads',\n",
       " 'estimate_tokens',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'floating_point_ops',\n",
       " 'forward',\n",
       " 'framework',\n",
       " 'from_pretrained',\n",
       " 'generate',\n",
       " 'generation_config',\n",
       " 'get_adapter_state_dict',\n",
       " 'get_buffer',\n",
       " 'get_extended_attention_mask',\n",
       " 'get_extra_state',\n",
       " 'get_head_mask',\n",
       " 'get_input_embeddings',\n",
       " 'get_memory_footprint',\n",
       " 'get_output_embeddings',\n",
       " 'get_parameter',\n",
       " 'get_position_embeddings',\n",
       " 'get_submodule',\n",
       " 'gradient_checkpointing_disable',\n",
       " 'gradient_checkpointing_enable',\n",
       " 'greedy_search',\n",
       " 'group_beam_search',\n",
       " 'half',\n",
       " 'init_weights',\n",
       " 'invert_attention_mask',\n",
       " 'ipu',\n",
       " 'is_gradient_checkpointing',\n",
       " 'is_loaded_in_4bit',\n",
       " 'is_loaded_in_8bit',\n",
       " 'is_parallelizable',\n",
       " 'load_adapter',\n",
       " 'load_state_dict',\n",
       " 'main_input_name',\n",
       " 'modules',\n",
       " 'name_or_path',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'num_parameters',\n",
       " 'parameters',\n",
       " 'post_init',\n",
       " 'prepare_inputs_for_generation',\n",
       " 'prune_heads',\n",
       " 'push_to_hub',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_for_auto_class',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_memory_hooks_state',\n",
       " 'resize_position_embeddings',\n",
       " 'resize_token_embeddings',\n",
       " 'retrieve_modules_from_names',\n",
       " 'reverse_bettertransformer',\n",
       " 'sample',\n",
       " 'save_pretrained',\n",
       " 'set_adapter',\n",
       " 'set_extra_state',\n",
       " 'set_input_embeddings',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'supports_gradient_checkpointing',\n",
       " 'tie_weights',\n",
       " 'to',\n",
       " 'to_bettertransformer',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'training',\n",
       " 'type',\n",
       " 'vit',\n",
       " 'warn_if_padding_and_no_attention_mask',\n",
       " 'warnings_issued',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "day_image_folder = './deer_detection/training_data/voc_day/JPEGImages/'\n",
    "night_image_folder = './deer_detection/training_data/voc_night/JPEGImages/'\n",
    "day_annotation_folder = './deer_detection/training_data/voc_day/Annotations/'\n",
    "night_annotation_folder = './deer_detection/training_data/voc_night/Annotations/'\n",
    "\n",
    "def read_content(xml_file: str):\n",
    "\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    list_with_all_boxes = []\n",
    "    filename = root.find('filename').text\n",
    "    folder = root.find('folder').text\n",
    "    size_node = root.find('size')\n",
    "\n",
    "    width = int(size_node.find('width').text)\n",
    "    height = int(size_node.find('height').text)\n",
    "    depth = int(size_node.find('depth').text)\n",
    "\n",
    "\n",
    "    for boxes in root.iter('object'):\n",
    "        name = boxes.find(\"name\").text\n",
    "        pose = boxes.find(\"pose\").text\n",
    "        truncated = int(boxes.find(\"truncated\").text)\n",
    "        difficult = int(boxes.find(\"difficult\").text)\n",
    "        ymin, xmin, ymax, xmax = None, None, None, None\n",
    "\n",
    "        ymin = int(boxes.find(\"bndbox/ymin\").text)\n",
    "        xmin = int(boxes.find(\"bndbox/xmin\").text)\n",
    "        ymax = int(boxes.find(\"bndbox/ymax\").text)\n",
    "        xmax = int(boxes.find(\"bndbox/xmax\").text)\n",
    "\n",
    "        dict_with_single_box = {\n",
    "            'name': name,\n",
    "            'pose': pose,\n",
    "            'truncated': truncated,\n",
    "            'difficult': difficult,\n",
    "            'xmin': xmin,\n",
    "            'ymin': ymin,\n",
    "            'xmax': xmax,\n",
    "            'ymax': ymax\n",
    "        }\n",
    "        list_with_all_boxes.append(dict_with_single_box)\n",
    "    return {\n",
    "        'full_path': str(xml_file.absolute()),\n",
    "        'size': {\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'depth': depth\n",
    "        },\n",
    "        'boxes': list_with_all_boxes\n",
    "    }\n",
    "\n",
    "def get_xml_files(folder: str):\n",
    "    xml_files = {}\n",
    "    for xml_file in Path(folder).glob('*.xml'):\n",
    "        xml_files[xml_file.stem] = read_content(xml_file)\n",
    "    return xml_files\n",
    "\n",
    "# day_xml_dict = get_xml_files(day_annotation_folder)\n",
    "# night_xml_dict = get_xml_files(night_annotation_folder) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing VOC files...: 100%|██████████| 15314/15314 [00:05<00:00, 2555.23it/s]\n",
      "Importing VOC files...: 100%|██████████| 10345/10345 [00:04<00:00, 2510.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from pylabel import importer\n",
    "import pandas as pd\n",
    "\n",
    "day_annotation_folder = './deer_detection/training_data/voc_day/Annotations/'\n",
    "night_annotation_folder = './deer_detection/training_data/voc_night/Annotations/'\n",
    "\n",
    "path_to_images = \"../JPEGImages/\"\n",
    "\n",
    "day_dataset = importer.ImportVOC(path=day_annotation_folder, path_to_images=path_to_images)\n",
    "night_dataset = importer.ImportVOC(path=night_annotation_folder, path_to_images=path_to_images)\n",
    "\n",
    "datasets = {\n",
    "    \"day\": day_dataset,\n",
    "    \"night\": night_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_mapping = dict(zip(datasets[\"day\"].df['cat_id'].unique(), datasets[\"day\"].df['cat_name'].unique()))\n",
    "\n",
    "# Apply the same mapping to the night dataset\n",
    "datasets[\"night\"].df['cat_name'] = datasets[\"night\"].df['cat_id'].map(cat_mapping)\n",
    "datasets[\"night\"].df['cat_id'] = datasets[\"night\"].df['cat_name'].map(dict(zip(datasets[\"night\"].df['cat_name'].unique(), datasets[\"night\"].df['cat_id'].unique())))\n",
    "\n",
    "night_cat_mapping = dict(zip(datasets[\"night\"].df['cat_id'].unique(), datasets[\"night\"].df['cat_name'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "datasets['day'].df['img_folder'] = 'voc_day/JPEGImages/'\n",
    "datasets['night'].df['img_folder'] = 'voc_night/JPEGImages/'\n",
    "datasets['combined'] = copy.deepcopy(datasets['day'])\n",
    "datasets['combined'].df = pd.concat([datasets['day'].df, datasets['night'].df]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: day\n",
      "Number of images: 15313\n",
      "Number of classes: 17\n",
      "Classes:['Leopard', 'AmurTiger', 'Badger', 'BlackBear', 'Cow', 'RaccoonDog', 'Dog', 'Hare', 'LeopardCat', 'MuskDeer', 'RedFox', 'RoeDeer', 'Sable', 'SikaDeer', 'Weasel', 'WildBoar', 'Y.T.Marten']\n",
      "Class counts:\n",
      "SikaDeer      1849\n",
      "RoeDeer       1686\n",
      "WildBoar      1526\n",
      "Cow           1364\n",
      "Dog           1360\n",
      "Leopard       1102\n",
      "LeopardCat    1045\n",
      "RedFox        1001\n",
      "BlackBear      973\n",
      "Y.T.Marten     968\n",
      "Badger         955\n",
      "AmurTiger      828\n",
      "Weasel         755\n",
      "RaccoonDog     352\n",
      "MuskDeer       271\n",
      "Sable          192\n",
      "Hare            20\n",
      "Name: cat_name, dtype: int64\n",
      "Dataset: night\n",
      "Number of images: 10344\n",
      "Number of classes: 17\n",
      "Classes:['Leopard', 'AmurTiger', 'Badger', 'BlackBear', 'Cow', 'RaccoonDog', 'Dog', 'Hare', 'LeopardCat', 'MuskDeer', 'RedFox', 'RoeDeer', 'Sable', 'SikaDeer', 'Weasel', 'WildBoar', 'Y.T.Marten']\n",
      "Class counts:\n",
      "MuskDeer      1264\n",
      "Dog           1261\n",
      "LeopardCat    1031\n",
      "Hare           937\n",
      "RedFox         872\n",
      "WildBoar       831\n",
      "SikaDeer       702\n",
      "RoeDeer        563\n",
      "AmurTiger      547\n",
      "Weasel         541\n",
      "Leopard        491\n",
      "Sable          443\n",
      "BlackBear      435\n",
      "Badger         409\n",
      "Y.T.Marten     136\n",
      "RaccoonDog     125\n",
      "Cow            111\n",
      "Name: cat_name, dtype: int64\n",
      "Dataset: combined\n",
      "Number of images: 25657\n",
      "Number of classes: 17\n",
      "Classes:['Leopard', 'AmurTiger', 'Badger', 'BlackBear', 'Cow', 'RaccoonDog', 'Dog', 'Hare', 'LeopardCat', 'MuskDeer', 'RedFox', 'RoeDeer', 'Sable', 'SikaDeer', 'Weasel', 'WildBoar', 'Y.T.Marten']\n",
      "Class counts:\n",
      "Dog           2621\n",
      "SikaDeer      2551\n",
      "WildBoar      2357\n",
      "RoeDeer       2249\n",
      "LeopardCat    2076\n",
      "RedFox        1873\n",
      "Leopard       1593\n",
      "MuskDeer      1535\n",
      "Cow           1475\n",
      "BlackBear     1408\n",
      "AmurTiger     1375\n",
      "Badger        1364\n",
      "Weasel        1296\n",
      "Y.T.Marten    1104\n",
      "Hare           957\n",
      "Sable          635\n",
      "RaccoonDog     477\n",
      "Name: cat_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for dataset_name, dataset in datasets.items():\n",
    "    print(f\"Dataset: {dataset_name}\")\n",
    "    print(f\"Number of images: {dataset.analyze.num_images}\")\n",
    "    print(f\"Number of classes: {dataset.analyze.num_classes}\")\n",
    "    print(f\"Classes:{dataset.analyze.classes}\")\n",
    "    print(f\"Class counts:\\n{dataset.analyze.class_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exporting to COCO file...: 100%|██████████| 26946/26946 [00:14<00:00, 1826.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./deer_detection/training_data/coco_combined.json']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['combined'].export.dataset = datasets['combined']\n",
    "datasets['combined'].export.ExportToCoco(output_path='./deer_detection/training_data/coco_combined.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(datasets['combined'].visualize.ShowBoundingBoxes(1000))\n",
    "# display(dataset.visualize.ShowBoundingBoxes(\"BloodImage_00315.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ReindexCatIds',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'analyze',\n",
       " 'df',\n",
       " 'export',\n",
       " 'labeler',\n",
       " 'name',\n",
       " 'path_to_annotations',\n",
       " 'splitter',\n",
       " 'visualize']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the two datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\William.White\\Documents\\Coding\\Python\\deer_detection\\train_deer.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Fine tune the model\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m TrainingArguments\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     output_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./results\u001b[39;49m\u001b[39m'\u001b[39;49m,          \u001b[39m# output directory\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     num_train_epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,              \u001b[39m# total number of training epochs\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     per_device_train_batch_size\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,   \u001b[39m# batch size per device during training\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     per_device_eval_batch_size\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,    \u001b[39m# batch size for evaluation\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     warmup_steps\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,                \u001b[39m# number of warmup steps for learning rate scheduler\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     weight_decay\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m,               \u001b[39m# strength of weight decay\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     logging_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./logs\u001b[39;49m\u001b[39m'\u001b[39;49m,            \u001b[39m# directory for storing logs\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     logging_steps\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Prepare the data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/William.White/Documents/Coding/Python/deer_detection/train_deer.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m DataCollatorForObjectDetection\n",
      "File \u001b[1;32m<string>:115\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, sharded_ddp, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, include_inputs_for_metrics, fp16_backend, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, include_tokens_per_second)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\William.White\\AppData\\Local\\miniconda3\\envs\\lender_approval\\lib\\site-packages\\transformers\\training_args.py:1436\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1430\u001b[0m     \u001b[39mif\u001b[39;00m version\u001b[39m.\u001b[39mparse(version\u001b[39m.\u001b[39mparse(torch\u001b[39m.\u001b[39m__version__)\u001b[39m.\u001b[39mbase_version) \u001b[39m==\u001b[39m version\u001b[39m.\u001b[39mparse(\u001b[39m\"\u001b[39m\u001b[39m2.0.0\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16:\n\u001b[0;32m   1431\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m--optim adamw_torch_fused with --fp16 requires PyTorch>2.0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1433\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1434\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1435\u001b[0m     \u001b[39mand\u001b[39;00m is_torch_available()\n\u001b[1;32m-> 1436\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1437\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1438\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1439\u001b[0m     \u001b[39mand\u001b[39;00m (get_xla_device_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice) \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1440\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp16_full_eval)\n\u001b[0;32m   1441\u001b[0m ):\n\u001b[0;32m   1442\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1443\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFP16 Mixed precision training with AMP or APEX (`--fp16`) and FP16 half precision evaluation\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1444\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m (`--fp16_full_eval`) can only be used on CUDA or NPU devices or certain XPU devices (with IPEX).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1445\u001b[0m     )\n\u001b[0;32m   1447\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1448\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframework \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1449\u001b[0m     \u001b[39mand\u001b[39;00m is_torch_available()\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16 \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbf16_full_eval)\n\u001b[0;32m   1457\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\William.White\\AppData\\Local\\miniconda3\\envs\\lender_approval\\lib\\site-packages\\transformers\\training_args.py:1901\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1897\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1898\u001b[0m \u001b[39mThe device used by this process.\u001b[39;00m\n\u001b[0;32m   1899\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1900\u001b[0m requires_backends(\u001b[39mself\u001b[39m, [\u001b[39m\"\u001b[39m\u001b[39mtorch\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m-> 1901\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_devices\n",
      "File \u001b[1;32mc:\\Users\\William.White\\AppData\\Local\\miniconda3\\envs\\lender_approval\\lib\\site-packages\\transformers\\utils\\generic.py:54\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, obj, objtype)\u001b[0m\n\u001b[0;32m     52\u001b[0m cached \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, attr, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m cached \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     cached \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfget(obj)\n\u001b[0;32m     55\u001b[0m     \u001b[39msetattr\u001b[39m(obj, attr, cached)\n\u001b[0;32m     56\u001b[0m \u001b[39mreturn\u001b[39;00m cached\n",
      "File \u001b[1;32mc:\\Users\\William.White\\AppData\\Local\\miniconda3\\envs\\lender_approval\\lib\\site-packages\\transformers\\training_args.py:1801\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[0;32m   1800\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_accelerate_available(min_version\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m0.20.1\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1801\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m   1802\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1803\u001b[0m         )\n\u001b[0;32m   1804\u001b[0m     AcceleratorState\u001b[39m.\u001b[39m_reset_state(reset_partial_state\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1805\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistributed_state \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import os\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, annotations, feature_extractor, train=True):\n",
    "        self.annotations = annotations\n",
    "        self.train = train\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # read in PIL image and target in COCO format\n",
    "        img, target = super(CocoDetection, self).__getitem__(idx)\n",
    "        \n",
    "        # preprocess image and target (converting target to DETR format, resizing + normalization of both image and target)\n",
    "        image_id = self.ids[idx]\n",
    "        target = {'image_id': image_id, 'annotations': target}\n",
    "        # Target looks like {\"id\": 125686, \"category_id\": 0, \"iscrowd\": 0, \"segmentation\": [[164.81, 417.51,......167.55, 410.64]], \"image_id\": 242287, \"area\": 42061.80340000001, \"bbox\": [19.23, 383.18, 314.5, 244.46]}(x, y, width, height)\n",
    "        encoding = self.feature_extractor(images=img, annotations=target, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].squeeze() # remove batch dimension\n",
    "        target = encoding[\"labels\"][0] # remove batch dimension\n",
    "\n",
    "        return pixel_values, target\n",
    "\n",
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"hustvl/yolos-small\", size=512, max_size=864)\n",
    "\n",
    "train_dataset = CocoDetection(img_folder=(dataset.location + '/train'), feature_extractor=feature_extractor)\n",
    "val_dataset = CocoDetection(img_folder=(dataset.location + '/valid'), feature_extractor=feature_extractor, train=False)\n",
    "\n",
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lender_approval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
